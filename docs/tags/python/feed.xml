<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>python on Varun Pant</title><link>https://varunpant.com/tags/python/</link><description>Recent content in python on Varun Pant</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 25 May 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://varunpant.com/tags/python/feed.xml" rel="self" type="application/rss+xml"/><item><title>Cloud composer orchestration via cloud build</title><link>https://varunpant.com/posts/cloud-composer-orchestration-via-cloud-build/</link><pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/cloud-composer-orchestration-via-cloud-build/</guid><description>Cloud composer orchestration via cloud build Google cloud composer is a managed apache airflow service that helps create, schedule, monitor and manage workflows.Cloud Composer automation helps you create Airflow environments quickly and use Airflow-native tools, such as the powerful Airflow web interface and command line tools, so you can focus on your workflows and not your infrastructure.
In this article I will descibe how an engineering team can manage, develop and publish DAGS after running a full CI/CD build pipeline using google cloud build .</description></item><item><title>Simple Forecasting</title><link>https://varunpant.com/posts/simple-forecasting/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/simple-forecasting/</guid><description>Timeseries financial forecasting Recently , I have been looking into various ways to forecast a time series dataset. This is an old pursuit in the field of statistics and there are many well known ways to achieve this.
In this post I will demonstrate a very basic (Naive) approach of forecasting a quarterly dataset of sales figure, by using previous 4 years (16 quarters) and forecasting/predicting the next 1 year of sales aggregate.</description></item><item><title>how to install the latest python 3 on mac</title><link>https://varunpant.com/posts/how-to-install-the-latest-python-3-on-mac/</link><pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-install-the-latest-python-3-on-mac/</guid><description>Here is a quick guide on installing Python3 on a mac
Installation brew update brew upgrade sudo mkdir -p /usr/local/Frameworks sudo chown -R $(whoami) /usr/local/* brew install python3 brew link python3 brew doctor Aliasing echo &amp;#34;alias python=/usr/local/bin/python3.7&amp;#34; &amp;gt;&amp;gt; ~/.zshrc or
echo &amp;#34;alias python=/usr/local/bin/python3.7&amp;#34; &amp;gt;&amp;gt; ~/.bashrc You could probably have just done this as well
alias python=&amp;#39;python3&amp;#39; alias pip=&amp;#39;pip3&amp;#39; I hope this is useful</description></item><item><title>download file using webdriver firefox and python selenium</title><link>https://varunpant.com/posts/download-file-using-webdriver-firefox-and-python-selenium/</link><pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/download-file-using-webdriver-firefox-and-python-selenium/</guid><description>Selenium is one of my favourite tool for automation.
In this post, I will demonstrate some basic code to download a file from a website in a headless mode , and also provide a docker file to make things simpler.
Python Code Here is some basic code which will make an attempt to download a **7zip exe. **
from pyvirtualdisplay import Display from selenium import webdriver from selenium.webdriver.support.ui import WebDriverWait from selenium.</description></item><item><title>web crawling or scraping using scrapy in python</title><link>https://varunpant.com/posts/web-crawling-or-scraping-using-scrapy-in-python/</link><pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/web-crawling-or-scraping-using-scrapy-in-python/</guid><description>Scrapy is a very popular web scraping/crawling framework, I have been using it for quite some time now.
In this post, I will demonstrate creating a very basic web crawler.
Install Scrapy Installation is via pip pip install scrapy
Minimalistic Code A very simple scraper is created like this
To Run , simply type scrapy runspider scraper.py
Running, above code will output something like below
2018-12-02 14:01:18 [scrapy.utils.log] INFO: Scrapy 1.</description></item><item><title>how to make https requests with python httplib2 ssl</title><link>https://varunpant.com/posts/how-to-make-https-requests-with-python-httplib2-ssl/</link><pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-make-https-requests-with-python-httplib2-ssl/</guid><description>Here are few snippets to make secure http requests using various python libraries.
httplib2 import httplib2 link = &amp;#34;https://example.com h = httplib2.Http(&amp;#34;.cache&amp;#34;) r, content = h.request(link, &amp;#34;GET&amp;#34;) another exmaple import httplib2 h = httplib2.Http(&amp;#34;.cache&amp;#34;) h.add_credentials(&amp;#39;user&amp;#39;, &amp;#39;pass&amp;#39;) r, content = h.request(&amp;#34;https://api.github.com&amp;#34;, &amp;#34;GET&amp;#34;) print r[&amp;#39;status&amp;#39;] print r[&amp;#39;content-type&amp;#39;] Urllib2 Here is a simmilar example using urlib2 for comparison and lines of code.
import urllib2 gh_url = &amp;#39;https://example.com&amp;#39; auth_handler = urllib2.HTTPBasicAuthHandler() auth_handler.add_password(None, gh_url, &amp;#39;user&amp;#39;, &amp;#39;password&amp;#39;) opener = urllib2.</description></item><item><title>how to read json from web http request of url via python urllib</title><link>https://varunpant.com/posts/how-to-read-json-from-web-http-request-of-url-via-python-urllib/</link><pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-read-json-from-web-http-request-of-url-via-python-urllib/</guid><description>I generally am looking for a quick snippet to issue an http request using urllib2 lib.
Here is a quick snippet to do so
import urllib2 import json from pprint import pprint req = urllib2.Request(url) opener = urllib2.build\_opener() f = opener.open(req) #data varibale recieves the parsed json data = json.loads(f.read()) print len(data) for r in data: pprint(r) print &amp;#34;-&amp;#34;*50 Hope this helps</description></item><item><title>minimum insertions to form a palindrome</title><link>https://varunpant.com/posts/minimum-insertions-to-form-a-palindrome/</link><pubDate>Sun, 15 Oct 2017 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/minimum-insertions-to-form-a-palindrome/</guid><description>Brute-force approach Here I present a few approaches to deduce &amp;ldquo;minimum insertions&amp;rdquo; required to convert a string into a palindrome.
The basic brute force approach is quite simple, given a string with length L, start comparing, the first character from left and the last character while scanning inwards.
Here is a basic test for a palindrome.
L = len(s) for i in range(L): if s[i] != s[L - i - 1]: return False,i,L-i -1 return True,0,0 The above code returns True if the string is a palindrome or returns False with mismatching indices.</description></item><item><title>merge sort in python</title><link>https://varunpant.com/posts/merge-sort-in-python/</link><pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/merge-sort-in-python/</guid><description>Many useful algorithms are recursive in structure: to solve a given problem, they call themselves recursively one or more times to deal with closely related subproblems. These algorithms typically follow a divide-and-conquer approach: they break the problem into several subproblems that are similar to the original problem but smaller in size, solve the subproblems recursively, and then combine these solutions to create a solution to the original problem.
The divide-and-conquer paradigm involves three steps at each level of the recursion:</description></item><item><title>Using Geotiff as datasource via gdal</title><link>https://varunpant.com/posts/using-geotiff-as-datasource-via-gdal/</link><pubDate>Wed, 21 Dec 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/using-geotiff-as-datasource-via-gdal/</guid><description>Recently, I have been working on algorithms which needs elevation data as well as Land Cover data, with world coverage. Google has an excellent elevation API however free usage comes with a limit.
While searching, I came across a dataset in geotiff format for landcover as well as a processed version of world elevation. Elevation data comes in various resolution (250m,500m,1km), landcover is 500m .
So how do we read it ?</description></item><item><title>How to create fishnets or geospatial grids</title><link>https://varunpant.com/posts/how-to-create-fishnets-or-geospatial-grids/</link><pubDate>Sun, 11 Dec 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-create-fishnets-or-geospatial-grids/</guid><description>There are many use cases in GIS world, where the information has to be aggregated, an easy way to achieve this is via gridding or binning, where the area of interest is divided into small sections called grids or bins.
These sections are mostly of rectangular form (which can be easily converted into geotiffs), but in some cases even circles or hexagons are also used.
You can read a good tutorial from mapbox using Qgis with a mmqgis plugin here.</description></item><item><title>How to transform projections between Spherical Mercator and EPSG 4326</title><link>https://varunpant.com/posts/how-to-transform-projections-between-spherical-mercator-and-epsg-4326/</link><pubDate>Sat, 10 Dec 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-transform-projections-between-spherical-mercator-and-epsg-4326/</guid><description>Projections in GIS are commonly referred to by their “EPSG” codes, these are identifiers managed by the European Petroleum Survey Group.
One common identifier is “EPSG:4326”, which describes maps where latitude and longitude are treated as X/Y values.
Spherical Mercator has an official designation of EPSG:3857. However, before this was established, a large amount of software used the identifier EPSG:900913. This is an unofficial code, but is still the commonly usedin many GIS systems.</description></item><item><title>How to Query a Shape file for Point inside a polygon using ogr python</title><link>https://varunpant.com/posts/how-to-query-a-shape-file-for-point-inside-a-polygon-using-ogr-python/</link><pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-query-a-shape-file-for-point-inside-a-polygon-using-ogr-python/</guid><description>Recently I was trying to build a quick geo lookup service in python, which could be used like an &amp;ldquo;info tool&amp;rdquo; in QGIS. This task is trivial in almost all geospatial databases, however I wasn&amp;rsquo;t able to find much online around querying a shape file.
In this post I will demonstrate a simple python code to query a shape file which contains world countries. The file can be downloaded from here.</description></item><item><title>Binary Search Tree in python</title><link>https://varunpant.com/posts/binary-search-tree-in-python/</link><pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/binary-search-tree-in-python/</guid><description>BST data structure supports many dynamic-set operations including
Search Minimum Maximum Predecessor Successor Insert Delete These basic operations allow us to treat this data structure both as a dictionary and as a priority queue.
Basic operations on a binary tree takes time proportional to the height of the tree, O(lg n) [worst case] and even O(n) if the tree is a linear chain.
If you want to learn more about practical application of these trees check this post out.</description></item><item><title>Heap Sort in python</title><link>https://varunpant.com/posts/heap-sort/</link><pubDate>Mon, 25 Jul 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/heap-sort/</guid><description>The (binary) heap data structure is an array object that we can view as a nearly complete binary tree. Each node of the tree corresponds to an element of the array. The tree is completely filled on all levels except possibly the lowest, which is filled from the left up to a point. An array A that represents a heap is an object with two attributes:
length, which (as usual) gives the number of elements in the array.</description></item><item><title>Insertion sort in python</title><link>https://varunpant.com/posts/insertion-sort-in-python/</link><pubDate>Fri, 22 Jul 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/insertion-sort-in-python/</guid><description>Insertion sort, is an efficient algorithm for sorting a small number of elements.
Insertion sort works the way many people sort a hand of playing cards. We start with an empty left hand and the cards face down on the table. We then remove one card at a time from the table and insert it into the correct position in the left hand.
To find the correct position for a card, we compare it with each of the cards already in the hand, from right to left.</description></item><item><title>Read GAE Admin Backups fromLevelDB format and export GAE Entities using bulkloader</title><link>https://varunpant.com/posts/read-gae-admin-backups-fromleveldb-format-and-export-gae-entities-using-bulkloader/</link><pubDate>Mon, 11 Jan 2016 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/read-gae-admin-backups-fromleveldb-format-and-export-gae-entities-using-bulkloader/</guid><description>Google datastore is pretty awesome when one needs a quick no-sql data storage. However recently I have experienced a problem in exporting my GAE Datastore as csv and in certain cases as a line delimited Json file. Its not very hard to do so and perhaps the easiest way to handle such thing is to write an export handler in you web app, however, there are alternative ways which I have highlighted below.</description></item><item><title>Bubble-sort in python</title><link>https://varunpant.com/posts/bubble-sort-in-python/</link><pubDate>Thu, 23 Jul 2015 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/bubble-sort-in-python/</guid><description>Bubble sort is a sorting algo that repeatedly steps through the list to be sorted, compares each pair of adjacent items and swaps them if they are in the wrong order.
It is a popular, but inefficient sorting algo, it has worst-case and average complexity both О(n2), where n is the number of items being sorted.
Here is an implementation in python
count = len(B) for i in xrange(count): for j in xrange(count-1,i,-1): #print &amp;#34;compairing %i with %i&amp;#34;%(B[j],B[j-1]) if B[j] &amp;lt; B[j - 1]: temp = B[j] B[j] = B[j - 1] B[j - 1] = temp #print &amp;#34;Swapping %i with %i&amp;#34;%(B[j],B[j-1]) #print &amp;#34;Transformed Array: &amp;#34; , B B = [6,5,3,1,8,7,2,4] print &amp;#34;Unsorted: &amp;#34;, B bubbleSort(B) print &amp;#34;Bubble Sorted: &amp;#34;, B Hope this helps</description></item><item><title>longest palindrome in a string</title><link>https://varunpant.com/posts/longest-palindrome-in-a-string/</link><pubDate>Wed, 15 Oct 2014 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/longest-palindrome-in-a-string/</guid><description>def isPailenDrome(s): if len(s)==1: return False L = len(s) for i in range(L): if s[i] != s[L-1-i]: return False return True def longestPalindrome(s): L = len(s) if len(s)&amp;lt;=1: return s if isPailenDrome(s): return s p = {} for u in range(L): for v in range(u+1,L+1): k = s[u:v] # print k,isPailenDrome(k) if isPailenDrome(k): p[len(k)] = k if len(p) &amp;gt; 0: return p[sorted(p,reverse = True)[0]] return s[0]</description></item><item><title>print two-dimensional array in spiral order</title><link>https://varunpant.com/posts/print-two-dimensional-array-in-spiral-order/</link><pubDate>Wed, 15 Oct 2014 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/print-two-dimensional-array-in-spiral-order/</guid><description>So I saw this problem in a book today about printing a 2d matrix in spiral order
Here are two solutions to it
Solution one. def printSpiralTL(m,x1,y1,x2,y2): for i in range(x1,x2): print m[y1][i] for j in range(y1+1,y2+1): print m[j][x2-1] if x2-x1 &amp;gt; 0: printSpiralBL(m, x1, y1 + 1, x2-1, y2) def printSpiralBL(m,x1,y1,x2,y2): for i in range(x2-1,x1-1,-1): print m[y2][i] for j in range(y2-1,y1-1,-1): print m[j][x1] if x2-x1 &amp;gt; 0: printSpiralTL(m, x1+1, y1, x2, y2-1) m = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 0, 1, 2], [3, 4, 5, 6], [7, 8, 9, 1] ] Output:</description></item><item><title>merge two sorted arrays in python</title><link>https://varunpant.com/posts/merge-two-sorted-arrays-in-python/</link><pubDate>Sat, 11 Oct 2014 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/merge-two-sorted-arrays-in-python/</guid><description>Here is a quick code snippet to merge two sorted arrays in python
merged = [] l = 0 r = 0 for i in range(len(a)+len(b) ): lval = None rval = None if l &amp;lt; len(a): lval = a[l] if r &amp;lt; len(b): rval = b[r] if (lval &amp;lt; rval and rval and lval) or rval == None: merged.append(lval) l+=1 elif (lval &amp;gt;= rval and rval and lval)or lval == None: merged.</description></item><item><title>Normalizing Ranges of Numbers</title><link>https://varunpant.com/posts/normalizing-ranges-of-numbers/</link><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/normalizing-ranges-of-numbers/</guid><description>Range Normalization is a normalization technique that allows you to map a number to a specific range.
Lets say that we have a data set where the values are in a range of 1 to 10, however we wish to normalise it to a range between 0 and 5
Mathematically speaking the equation comes down to
translated to Python
class Normaliser: def \_\_init\_\_(self,dH,dL,nH,nL): self.dH = dH self.dL = dL self.nH = nH self.</description></item><item><title>how to make a web crawler in python</title><link>https://varunpant.com/posts/how-to-make-a-web-crawler-in-python/</link><pubDate>Sat, 01 Feb 2014 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-make-a-web-crawler-in-python/</guid><description>Here is a very simple web crawler in python
import sys, thread, Queue, re, urllib, urlparse, time, os, sys dupcheck = set() q = Queue.Queue(100) q.put(&amp;#34;http://www.varunpant.com&amp;#34;) def queueURLs(html, origLink): for url in re.findall(&amp;#39;&amp;#39;&amp;#39;]+href=[&amp;#34;&amp;#39;](.[^&amp;#34;&amp;#39;]+)[&amp;#34;&amp;#39;]&amp;#39;&amp;#39;&amp;#39;, html, re.I): link = url.split(&amp;#34;#&amp;#34;, 1)[0] if url.startswith(&amp;#34;http&amp;#34;) else &amp;#39;{uri.scheme}://{uri.netloc}&amp;#39;.format(uri=urlparse.urlparse(origLink)) + url.split(&amp;#34;#&amp;#34;, 1)[0] if link in dupcheck: continue dupcheck.add(link) if len(dupcheck) &amp;gt; 99999: dupcheck.clear() q.put(link) def getHTML(link): try: html = urllib.urlopen(link).read() print link # open(str(time.time()) + &amp;#34;.html&amp;#34;, &amp;#34;w&amp;#34;).</description></item><item><title>How to configure Apache mod_wsgi</title><link>https://varunpant.com/posts/how-to-configure-apache-mod_wsgi/</link><pubDate>Tue, 26 Feb 2013 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-configure-apache-mod_wsgi/</guid><description>I am a big fan and user of python. one of the most popular ways to create quick web app in python is via using mod wsgi.
The aim of mod_wsgi is to implement a simple to use Apache module which can host any Python application which supports the Python WSGI interface.
The module would be suitable for use in hosting high performance production web sites, as well as your average self managed personal sites running on web hosting services.</description></item><item><title>Serve the contents of any directory with Python's SimpleHTTPServer</title><link>https://varunpant.com/posts/serve-the-contents-of-any-directory-with-python-s-simplehttpserver/</link><pubDate>Fri, 08 Feb 2013 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/serve-the-contents-of-any-directory-with-python-s-simplehttpserver/</guid><description>Generally, when I am in a middle of prototyping a concept or in a need of quickly executing Ajax requests or using browser features which would need the page to be hosted on a web server, I use Python&amp;rsquo;s SimpleHTTPServer module.
Python&amp;rsquo;s SimpleHTTPServer is a great way of serve the contents of the current directory,all one needs to do is change directory and execute a command which will expose all contents as if they were hosted in a web page.</description></item><item><title>Basic authentication in web.py via attribute</title><link>https://varunpant.com/posts/basic-authentication-in-web-py-via-attribute/</link><pubDate>Wed, 23 Jan 2013 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/basic-authentication-in-web-py-via-attribute/</guid><description>Here I demonstrate the process of Basic Authentication in web.py python web framework.
There is a proof of concept article provided in the main site,however I just thought doing the same via an attribute might be a cleaner solution.
HTTP Basic authentication implementation is one of the easiest ways to secure web pages because it doesn&amp;rsquo;t require cookies, session handling, or the development of login pages. Rather, HTTP Basic authentication uses static headers which means that no handshakes have to be done in anticipation,however the n the credentials are passed as plain-text and could be intercepted.</description></item><item><title>Factorial in python</title><link>https://varunpant.com/posts/factorial-in-python/</link><pubDate>Tue, 14 Aug 2012 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/factorial-in-python/</guid><description>Mathematically, the formula for the factorial is as follows. If n is an integer greater than or equal to 1, then n ! = n ( n - 1)( n - 2)( n - 3) &amp;hellip; (3)(2)(1) If p = 0, then p ! = 1 by convention.
def factorial(n): if n == 0: return 1 else: return n * factorial(n-1) Hope this helps</description></item><item><title>Auto Complete with Redis (Python)</title><link>https://varunpant.com/posts/auto-complete-with-redis-python/</link><pubDate>Sun, 06 May 2012 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/auto-complete-with-redis-python/</guid><description>This is a quick port of auto complete implementation in ruby using Redis by antirez.
I like python and had little time to burn today, so here goes:
The file used for input is female-names.txt
Hope it helps :)</description></item><item><title>How To Install and use Python Web.py framework on Windows</title><link>https://varunpant.com/posts/how-to-install-and-use-python-webpy-framework-on-windows/</link><pubDate>Sun, 06 May 2012 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-install-and-use-python-webpy-framework-on-windows/</guid><description>Web.py has been one of my favorite web frameworks as its pretty easy to get cracking on it.
It&amp;rsquo;s super quick to install and one can come up with a prototype and rapid web services in matter of minutes.
Install on windows If you haven&amp;rsquo;t configured easy_install on windows, then read this article.
Once easy_install has been configured believe it or not, all you have to do is open a command prompt and type</description></item><item><title>How to setup easy_install on Windows</title><link>https://varunpant.com/posts/how-to-setup-easy_install-on-windows/</link><pubDate>Sun, 06 May 2012 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/how-to-setup-easy_install-on-windows/</guid><description>If one has been using python, then installing various libraries and modules is basically a breeze using easy_install utility, however for folks using windows, easy_install utility has to be setup properly before using it.
First lets make sure that python is properly installed and PYTHON_HOME environment variable is configured:
Install Python on Windows If not already installed download python installer from here.
After it&amp;rsquo;s done downloading, double click to run the installer, and select default options (unless you have other custom needs of course ).</description></item><item><title>Notepad++ with Python</title><link>https://varunpant.com/posts/notepad-with-python/</link><pubDate>Tue, 15 Jun 2010 00:00:00 +0000</pubDate><guid>https://varunpant.com/posts/notepad-with-python/</guid><description>After reading an excellent article by Kazi Manzur Rashidon setting up a development environment for Iron Ruby using Notepad++, I was immediately struck with an idea of using the same excellent tool with Python 2.6.
Now don’t get me wrong here, theoretically there is nothing wrong with IDLE, but having a light weight IDE for those who don’t want to use Pydevplugin for Aptanaor Eclipse, I think Notepad++ is indeed a nice little dev tool.</description></item></channel></rss>