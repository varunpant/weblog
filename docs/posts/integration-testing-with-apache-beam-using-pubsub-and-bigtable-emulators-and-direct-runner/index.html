<!doctype html><html lang=en><head><title>integration testing with apache beam using pubsub and bigtable emulators and direct runner ::
Varun Pant</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=" Summary # Recently I have been looking into ways to test my Apache Beam pipelines at work. Most common use cases of Beam generally involves either batch reading data from GCS and writing to analytical platforms such as Big Query or stream reading data from Pubsub and writing to perhaps Bigtable.
A pipelines consists of transforms and its generally easy to test them in isolation as a independent unit test per stage, however I am personally a big fan of &ldquo;end-to-end&rdquo; testing or “Integration testing” and this is where things can sometimes get tricky.
"><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://varunpant.com/posts/integration-testing-with-apache-beam-using-pubsub-and-bigtable-emulators-and-direct-runner/><link type=application/opensearchdescription+xml rel=search title="Varun Pant" href=//www.varunpant.com/opensearch.axd><link rel=me type=text/html href="//plus.google.com/108455320594011020517?rel=me"><link rel=me type=text/html href=//varunpant.com/feed><link rel=me type=text/html href=//twitter.com/varunpant><link rel=me type=text/html href=//www.facebook.com/varun.pant><meta name=msvalidate.01 content="B96ED99B0213B547253C91D27272A5E4"><meta name=google-site-verification content="yu9tlev9-FkUUc0UkPrKP-8ren886--1FcSINU0TJDY"><meta http-equiv=X-XRDS-Location content="//www.myopenid.com/xrds?username=varunpant.myopenid.com"><meta name=syndication content="//feeds.feedburner.com/varun.pant"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=https://varunpant.com/style.css><link rel=apple-touch-icon-precomposed sizes=144x144 href=https://varunpant.com/img/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=https://varunpant.com/img/favicon.png><link href=/fonts/Inter-Italic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-Regular.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-Medium.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-MediumItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-Bold.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-BoldItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><meta name=twitter:card content="summary"><meta name=twitter:title content="integration testing with apache beam using pubsub and bigtable emulators and direct runner"><meta name=twitter:description content="Summary # Recently I have been looking into ways to test my Apache Beam pipelines at work. Most common use cases of Beam generally involves either batch reading data from GCS and writing to analytical platforms such as Big Query or stream reading data from Pubsub and writing to perhaps Bigtable.
A pipelines consists of transforms and its generally easy to test them in isolation as a independent unit test per stage, however I am personally a big fan of “end-to-end” testing or “Integration testing” and this is where things can sometimes get tricky."><meta property="og:url" content="https://varunpant.com/posts/integration-testing-with-apache-beam-using-pubsub-and-bigtable-emulators-and-direct-runner/"><meta property="og:site_name" content="Varun Pant"><meta property="og:title" content="integration testing with apache beam using pubsub and bigtable emulators and direct runner"><meta property="og:description" content="Summary # Recently I have been looking into ways to test my Apache Beam pipelines at work. Most common use cases of Beam generally involves either batch reading data from GCS and writing to analytical platforms such as Big Query or stream reading data from Pubsub and writing to perhaps Bigtable.
A pipelines consists of transforms and its generally easy to test them in isolation as a independent unit test per stage, however I am personally a big fan of “end-to-end” testing or “Integration testing” and this is where things can sometimes get tricky."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-08-03T00:00:00+00:00"><meta property="article:modified_time" content="2018-08-03T00:00:00+00:00"><meta property="article:tag" content="Dataflow"><meta property="article:tag" content="Apache-Beam"><meta property="article:tag" content="Java"><meta property="article:tag" content="Google"><meta property="article:tag" content="Bigdata"><meta property="article:tag" content="Testing"><section><div id=ta class=advert><script type=text/javascript>google_ad_client="ca-pub-1110730152886910",google_ad_slot="7384719372",google_ad_width=468,google_ad_height=60</script><script type=text/javascript src=//pagead2.googlesyndication.com/pagead/show_ads.js></script></div></section></head><body class=light-theme><div class=container><header class=header><span class=header__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg>
</span><span class=logo__text>Varun Pant</span>
<span class=logo__cursor></span>
</a><span class=header__right><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/about>About</a></li><li><a href=/archives>Archives</a></li><li><a href=/feed.xml>Feed</a></li><li><a href=/showcase>Showcase</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/about>About</a></li><li><a href=/archives>Archives</a></li><li><a href=/feed.xml>Feed</a></li><li><a href=/showcase>Showcase</a></li></ul></nav><span class=menu-trigger><svg viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
</span><span class=theme-toggle><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><article class=post><h1 class=post-title>integration testing with apache beam using pubsub and bigtable emulators and direct runner</h1><div class=post-meta><time class=post-date>2018-08-03
</time><span class=post-author>— Written by </span><span class=post-read-time>— 4 min read</span></div><span class=post-tags><a href=https://varunpant.com/tags/dataflow/>#dataflow</a>&nbsp;
<a href=https://varunpant.com/tags/apache-beam/>#apache-beam</a>&nbsp;
<a href=https://varunpant.com/tags/java/>#java</a>&nbsp;
<a href=https://varunpant.com/tags/google/>#google</a>&nbsp;
<a href=https://varunpant.com/tags/bigdata/>#bigdata</a>&nbsp;
<a href=https://varunpant.com/tags/testing/>#testing</a>&nbsp;</span><div class=post-content><h3 id=summary>Summary
<a href=#summary class=h-anchor aria-hidden=true>#</a></h3><p>Recently I have been looking into ways to test my <strong>Apache Beam</strong> pipelines at work. Most common use cases of Beam generally involves either batch reading data from GCS and writing to analytical platforms such as Big Query or stream reading data from Pubsub and writing to perhaps Bigtable.</p><p>A pipelines consists of transforms and its generally easy to test them in isolation as a independent unit test per stage, however I am personally a big fan of &ldquo;end-to-end&rdquo; testing or “Integration testing” and this is where things can sometimes get tricky.</p><p>Apache beam has various <a href=https://beam.apache.org/documentation/runners/capability-matrix/>runners</a>, the" one of interest" for testing purposes is the <a href=https://beam.apache.org/documentation/runners/direct/>Direct runner</a>.</p><p>From the doc:</p><blockquote><p>The Direct Runner executes pipelines on your machine and is designed to validate that pipelines adhere to the Apache Beam model as closely as possible. Instead of focusing on efficient pipeline execution, the Direct Runner performs additional checks to ensure that users do not rely on semantics that are not guaranteed by the model. Some of these checks include:</p><ul><li>enforcing immutability of elements.</li><li>enforcing encodability of elements.</li><li>elements are processed in an arbitrary order at all points.</li><li>serialization of user functions (DoFn, CombineFn, etc.)</li></ul><p>It’s also important to realise the memory considerations as mentioned below.</p></blockquote><blockquote><p>Local execution is limited by the memory available in your local environment. It is highly recommended that you run your pipeline with data sets small enough to fit in local memory. You can create a small in-memory data set using a Create transform, or you can use a Read transform to work with small local or remote files. I am going to show an example where I have written a basic integration test which listens for some payload from pubsub emulator, transforms the data to Mutation and then writes it to BigTable emulator, there are no aggregations performed hence every thing works in global window and triggering of a write is immediate. This example can also serve as a good way to front your data warehouse with apache beam for dynamically scalable writing,i.e as the pubsub message load would increase, beam would add more workers and as the load would decrease beam would reduce the workers.</p></blockquote><h4 id=setup-pubsub-emulator>SetUp PubSub Emulator
<a href=#setup-pubsub-emulator class=h-anchor aria-hidden=true>#</a></h4><p>Guide is <a href=https://cloud.google.com/pubsub/docs/emulator>here</a>.</p><h5 id=code>Code
<a href=#code class=h-anchor aria-hidden=true>#</a></h5><pre tabindex=0><code class=language-gcloud data-lang=gcloud>gcloud components update
gcloud beta emulators pubsub start [options]
</code></pre><p>optional step</p><pre tabindex=0><code class=language-$(gcloud data-lang=$(gcloud></code></pre><p>*You don’t need to run the optional step above as we would supply the url in the beam options. *</p><h4 id=setup-bigtable-emulator>SetUp BigTable Emulator
<a href=#setup-bigtable-emulator class=h-anchor aria-hidden=true>#</a></h4><p>Guide is <a href=https://cloud.google.com/bigtable/docs/emulator>here</a>.</p><h5 id=code-1>Code
<a href=#code-1 class=h-anchor aria-hidden=true>#</a></h5><pre tabindex=0><code class=language-gcloud data-lang=gcloud>gcloud beta emulators bigtable start
</code></pre><p>*This step is required if you want to use <a href=https://cloud.google.com/bigtable/docs/cbt-overview>cbt</a> to point to BigTable to browse the data. *</p><pre tabindex=0><code class=language-$(gcloud data-lang=$(gcloud></code></pre><h3 id=code-2>Code
<a href=#code-2 class=h-anchor aria-hidden=true>#</a></h3><p>Here are the steps involved in the pipeline.</p><pre tabindex=0><code class=language-Pipeline data-lang=Pipeline>
       p.apply(&#34;ReadPubsubMessages&#34;,
              
              PubsubIO.readMessages().fromSubscription(options.getSubscription()))

              .apply(&#34;ConvertMessageToBTMutation&#34;, new PubsubMessageToBigTableMutation())


               .apply(&#34;WriteToBigTable&#34;,

                       CloudBigtableIO.writeToTable(

                               getConfigurationForTable(options).withTableId(BIGTABLE\_TABLE\_ID).build()
               ));

       p.run().waitUntilFinish();
</code></pre><p>The pipeline is triggered via main method which is extended to include a testing variable</p><pre tabindex=0><code class=language-public data-lang=public> 
       @Description(&#34;Pub/Sub subscription to read from&#34;)
       @Validation.Required
       @Default.String(&#34;projects/test-project/subscriptions/evtsToBigTbl&#34;)
       String getSubscription();

       void setSubscription(String value);

       @Description(&#34;The Google Cloud project ID for the Cloud Bigtable instance.&#34;)
       @Validation.Required
       @Default.String(&#34;BT-PROD-PROJECT&#34;)
       String getBigtableProjectId();

       void setBigtableProjectId(String bigtableProjectId);

       @Description(&#34;The Google Cloud Bigtable instance ID .&#34;)
       @Validation.Required
       @Default.String(&#34;BT-PROD-INSTANCE&#34;)
       String getBigtableInstanceId();

       void setBigtableInstanceId(String bigtableInstanceId);


       @Description(&#34;For integration test.&#34;)
       @Validation.Required
       @Default.Boolean(true)
       Boolean getTesting();

       void setTesting(Boolean testing);


   }
</code></pre><p>Insure that the project and instance id for bigtable matches those in the cofiguration file ~/.cbtrc for bigtable, you can check this by typing in cbt in the console.</p><pre tabindex=0><code class=language-EventListenerOptions data-lang=EventListenerOptions>               .as(EventListenerOptions.class);
       options.setProject(&#34;PubSubToBigTable&#34;);

       if (options.getTesting()) {

           options.setPubsubRootUrl(PUBSUB\_EMULATOR\_HOST);//must point to emulator http://localhost:8085
           options.setBigtableProjectId(BIGTABLE\_PROJECT\_ID);//must be the same as in ~/.cbtrc
           options.setBigtableInstanceId(BIGTABLE\_INSTANCE\_ID);//must be the same as in ~/.cbtrc

       }

       RunPipeLine(options);
</code></pre><p>The intreseting bits are as follows</p><h3 id=override-pubsuboptions-url-in-beam>Override PubsubOptions url in Beam
<a href=#override-pubsuboptions-url-in-beam class=h-anchor aria-hidden=true>#</a></h3><p>This was easy, just make sure your options extend org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions. This includes a method called options.setPubsubRootUrl, whcih then can be pointed to emulator.</p><h3 id=point-beam-to-bigtable-emulator>Point beam to BigTable Emulator.
<a href=#point-beam-to-bigtable-emulator class=h-anchor aria-hidden=true>#</a></h3><p>This took me ages to figure out and eventually after digging in the code I was able to locate a bunch of properties which must be overridden.</p><pre tabindex=0><code class=language-private data-lang=private>
      CloudBigtableTableConfiguration.Builder config = new CloudBigtableTableConfiguration.Builder()
               .withProjectId(options.getBigtableProjectId())
               .withInstanceId(options.getBigtableInstanceId());
               
       if (options.getTesting()) {
           config.withConfiguration(&#34;google.bigtable.instance.admin.endpoint.host&#34;, &#34;localhost&#34;)
                   .withConfiguration(&#34;google.bigtable.admin.endpoint.host&#34;, &#34;localhost&#34;)
                   .withConfiguration(&#34;google.bigtable.endpoint.host&#34;, &#34;localhost&#34;)
                   .withConfiguration(&#34;google.bigtable.endpoint.port&#34;, &#34;8086&#34;)
                   .withConfiguration(&#34;google.bigtable.use.plaintext.negotiation&#34;, &#34;true&#34;)
                   .withConfiguration(&#34;google.bigtable.grpc.read.partial.row.timeout.ms&#34;, &#34;5000&#34;);
       }

       return config;


   }
</code></pre><p>and thats it, calling StarterPipeline.main(new String[]{"&ndash;testing=true", &ldquo;&ndash;runner=DirectRunner&rdquo;}); should do the trick.</p><p>I will soon include full code.</p></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://varunpant.com/posts/web-crawling-or-scraping-using-scrapy-in-python/><span class=button__icon>←</span>
<span class=button__text>web crawling or scraping using scrapy in python</span>
</a></span><span class="button next"><a href=https://varunpant.com/posts/gdal-2-on-mac-with-homebrew/><span class=button__text>gdal 2 on mac with homebrew</span>
<span class=button__icon>→</span></a></span></div></div><div id=blog-comments><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//varunpant.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></article></div><footer class=footer><div class=footer__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg>
</span><span class=logo__text>Varun Pant</span>
<span class=logo__cursor></span></a><div class=copyright><span>© 2025 Powered by <a href=https://gohugo.io target=_blank rel=noopener>Hugo</a></span>
<span><a href=https://github.com/panr/hugo-theme-hello-friend target=_blank>Theme</a> made by <a href=https://github.com/panr target=_blank>panr</a></span></div></div></footer><script type=text/javascript src=/bundle.min.js></script><section><div class=advert id=ta2><script type=text/javascript>google_ad_client="ca-pub-1110730152886910",google_ad_slot="1639236970",google_ad_width=728,google_ad_height=90</script><script type=text/javascript src=//pagead2.googlesyndication.com/pagead/show_ads.js></script></div></section><script id=dsq-count-scr src=//varunpant.disqus.com/count.js async></script></div></body></html>